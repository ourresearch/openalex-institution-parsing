{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import boto3\n",
    "import pickle\n",
    "from unidecode import unidecode\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification, DistilBertTokenizer\n",
    "from transformers import DataCollatorWithPadding, PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1695a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the path\n",
    "model_path = \"./path/to/model/artifacts/\"\n",
    "\n",
    "# Load the needed files\n",
    "with open(os.path.join(model_path, \"departments_list.pkl\"), \"rb\") as f:\n",
    "    departments_list = pickle.load(f)\n",
    "\n",
    "print(\"Loaded list of departments\")\n",
    "\n",
    "with open(os.path.join(model_path, \"full_affiliation_dict.pkl\"), \"rb\") as f:\n",
    "    full_affiliation_dict = pickle.load(f)\n",
    "\n",
    "print(\"Loaded affiliation dictionary\")\n",
    "\n",
    "with open(os.path.join(model_path, \"multi_inst_names_ids.pkl\"), \"rb\") as f:\n",
    "    multi_inst_names_ids = pickle.load(f)\n",
    "    \n",
    "print(\"Loaded list of institutions that have common name with other institutions.\")\n",
    "\n",
    "with open(os.path.join(model_path, \"countries_list_flat.pkl\"), \"rb\") as f:\n",
    "    countries_list_flat = pickle.load(f)\n",
    "\n",
    "print(\"Loaded flat list of countries\")\n",
    "\n",
    "with open(os.path.join(model_path, \"countries.json\"), \"r\") as f:\n",
    "    countries_dict = json.load(f)\n",
    "\n",
    "print(\"Loaded countries dictionary\")\n",
    "\n",
    "with open(os.path.join(model_path, \"city_country_list.pkl\"), \"rb\") as f:\n",
    "    city_country_list = pickle.load(f)\n",
    "\n",
    "print(\"Loaded strings of city/country combinations\")\n",
    "\n",
    "with open(os.path.join(model_path, \"affiliation_vocab.pkl\"), \"rb\") as f:\n",
    "    affiliation_vocab = pickle.load(f)\n",
    "    \n",
    "inverse_affiliation_vocab = {i:j for j,i in affiliation_vocab.items()}\n",
    "\n",
    "print(\"Loaded affiliation vocab\")\n",
    "\n",
    "# Load the tokenizers\n",
    "language_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\", return_tensors='tf')\n",
    "data_collator = DataCollatorWithPadding(tokenizer=language_tokenizer, \n",
    "                                        return_tensors='tf')\n",
    "\n",
    "basic_tokenizer = PreTrainedTokenizerFast(tokenizer_file=os.path.join(model_path, \"basic_model_tokenizer\"))\n",
    "\n",
    "# Load the models\n",
    "language_model = TFAutoModelForSequenceClassification.from_pretrained(os.path.join(model_path, \"language_model\"))\n",
    "language_model.trainable = False\n",
    "\n",
    "basic_model = tf.keras.models.load_model(os.path.join(model_path, \"basic_model\"), compile=False)\n",
    "basic_model.trainable = False\n",
    "\n",
    "def string_match_clean(text):\n",
    "    #replace \"&\" with \"and\"\n",
    "    if \"r&d\" not in text.lower():\n",
    "        text = text.replace(\" & \", \" and \")\n",
    "        \n",
    "    # take country out\n",
    "    if text.strip().endswith(\")\"):\n",
    "        for country in countries_list_flat:\n",
    "            if text.strip().endswith(f\"({country})\"):\n",
    "                text = text.replace(f\"({country})\", \"\")\n",
    "        \n",
    "    # use unidecode\n",
    "    text = unidecode(text.strip())\n",
    "    \n",
    "    # replacing common abbreviations\n",
    "    text = text.replace(\"Univ.\", \"University\")\n",
    "    text = text.replace(\"Lab.\", \"Laboratory\")\n",
    "    text = text.replace(\"U.S. Army\", \"United States Army\")\n",
    "    text = text.replace(\"U.S. Navy\", \"United States Navy\")\n",
    "    text = text.replace(\"U.S. Air Force\", \"United States Air Force\")\n",
    "    \n",
    "    # take out spaces, commas, dashes, periods, etcs\n",
    "    text = re.sub(\"[^0-9a-zA-Z]\", \"\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def get_country_in_string(text):\n",
    "    \"\"\"\n",
    "    Looks for countries in the affiliation string to be used in filtering later on.\n",
    "    \"\"\"\n",
    "    countries_in_string = []\n",
    "    _ = [countries_in_string.append(x) for x,y in countries_dict.items() if \n",
    "         np.max([1 if re.search(fr\"\\b{i}\\b\", text) else 0 for i in y]) > 0]\n",
    "    _ = [countries_in_string.append(x) for x,y in countries_dict.items() if \n",
    "         np.max([1 if re.search(fr\"\\b{i}\\b\", text.replace(\".\",\"\")) else 0 for i in y]) > 0]\n",
    "    return list(set(countries_in_string))\n",
    "\n",
    "def max_len_and_pad(tok_sent):\n",
    "    \"\"\"\n",
    "    Processes the basic model data to the correct input length.\n",
    "    \"\"\"\n",
    "    max_len = 128\n",
    "    tok_sent = tok_sent[:max_len]\n",
    "    tok_sent = tok_sent + [0]*(max_len - len(tok_sent))\n",
    "    return tok_sent\n",
    "\n",
    "\n",
    "def get_language(orig_aff_string):\n",
    "    \"\"\"\n",
    "    Guesses the language of the affiliation string to be used for filtering later.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        string_lang = detect(orig_aff_string)\n",
    "    except:\n",
    "        string_lang = 'en'\n",
    "        \n",
    "    return string_lang\n",
    "\n",
    "def get_initial_pred(orig_aff_string, string_lang, countries_in_string, comma_split_len):\n",
    "    \"\"\"\n",
    "    Initial hard-coded filtering of the affiliation text to ensure that meaningless strings\n",
    "    and strings in other languages are not given an institution.\n",
    "    \"\"\"\n",
    "    if string_lang in ['fa','ko','zh-cn','zh-tw','ja','uk','ru','vi','ar']:\n",
    "        init_pred = None\n",
    "    elif len(string_match_clean(str(orig_aff_string))) <=2:\n",
    "        init_pred = None\n",
    "    elif ((orig_aff_string.startswith(\"Dep\") | \n",
    "           orig_aff_string.startswith(\"School\") | \n",
    "           orig_aff_string.startswith(\"Ministry\")) & \n",
    "          (comma_split_len < 2) & \n",
    "          (not countries_in_string)):\n",
    "        init_pred = None\n",
    "    elif orig_aff_string in departments_list:\n",
    "        init_pred = None\n",
    "    elif string_match_clean(str(orig_aff_string).strip()) in city_country_list:\n",
    "        init_pred = None\n",
    "    elif re.search(r\"\\b(LIANG|YANG|LIU|XIE|JIA|ZHANG)\\b\", \n",
    "                   orig_aff_string):\n",
    "        for inst_name in [\"Hospital\",\"University\",\"School\",\"Academy\",\"Institute\",\n",
    "                          \"Ministry\",\"Laboratory\",\"College\"]:\n",
    "            if inst_name in str(orig_aff_string):\n",
    "                init_pred = 0\n",
    "                break\n",
    "            else:\n",
    "                init_pred = None\n",
    "                \n",
    "    elif re.search(r\"\\b(et al)\\b\", orig_aff_string):\n",
    "        if str(orig_aff_string).strip().endswith('et al'):\n",
    "            init_pred = None\n",
    "        else:\n",
    "            init_pred = 0\n",
    "    else:\n",
    "        init_pred = 0\n",
    "    return init_pred\n",
    "\n",
    "def get_language_model_prediction(decoded_text, all_countries):\n",
    "    \"\"\"\n",
    "    Preprocesses the decoded text and gets the output labels and scores for the language model.\n",
    "    \"\"\"\n",
    "    lang_tok_data = language_tokenizer(decoded_text, truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    data = data_collator(lang_tok_data)\n",
    "    all_scores, all_labels = tf.math.top_k(tf.nn.softmax(\n",
    "            language_model.predict([data['input_ids'], \n",
    "                                    data['attention_mask']]).logits).numpy(), 20)\n",
    "    \n",
    "    all_scores = all_scores.numpy().tolist()\n",
    "    all_labels = all_labels.numpy().tolist()\n",
    "    \n",
    "    final_preds_scores = []\n",
    "    for scores, labels, countries in zip(all_scores, all_labels, all_countries):\n",
    "        final_pred, final_score, mapping = get_final_basic_or_language_model_pred(scores, labels, countries,\n",
    "                                                                         affiliation_vocab, \n",
    "                                                                         inverse_affiliation_vocab)\n",
    "        final_preds_scores.append([final_pred, final_score, mapping])\n",
    "    \n",
    "    return final_preds_scores\n",
    "\n",
    "def get_basic_model_prediction(decoded_text, all_countries):\n",
    "    \"\"\"\n",
    "    Preprocesses the decoded text and gets the output labels and scores for the basic model.\n",
    "    \"\"\"\n",
    "    basic_tok_data = basic_tokenizer(decoded_text)['input_ids']\n",
    "    basic_tok_data = [max_len_and_pad(x) for x in basic_tok_data]\n",
    "    basic_tok_tensor = tf.convert_to_tensor(basic_tok_data, dtype=tf.int64)\n",
    "    all_scores, all_labels = tf.math.top_k(basic_model.predict(basic_tok_data), 20)\n",
    "    \n",
    "    all_scores = all_scores.numpy().tolist()\n",
    "    all_labels = all_labels.numpy().tolist()\n",
    "    \n",
    "    final_preds_scores = []\n",
    "    for scores, labels, countries in zip(all_scores, all_labels, all_countries):\n",
    "        final_pred, final_score, mapping = get_final_basic_or_language_model_pred(scores, labels, countries,\n",
    "                                                                         affiliation_vocab, \n",
    "                                                                         inverse_affiliation_vocab)\n",
    "        final_preds_scores.append([final_pred, final_score, mapping])\n",
    "    \n",
    "    return final_preds_scores\n",
    "\n",
    "\n",
    "def get_final_basic_or_language_model_pred(scores, labels, countries, vocab, inv_vocab):\n",
    "    \"\"\"\n",
    "    Takes the scores and labels from either model and performs a quick country matching\n",
    "    to see if the country found in the string can be matched to the country of the\n",
    "    predicted institution.\n",
    "    \"\"\"\n",
    "    mapped_labels = [inv_vocab[i] for i,j in zip(labels,scores) if i!=vocab[-1]]\n",
    "    scores = [j for i,j in zip(labels,scores) if i!=vocab[-1]]\n",
    "    final_pred = mapped_labels[0]\n",
    "    final_score = scores[0]\n",
    "    if not full_affiliation_dict[mapped_labels[0]]['country']:\n",
    "        pass\n",
    "    else:\n",
    "        if not countries:\n",
    "            pass\n",
    "        else:\n",
    "            for pred,score in zip(mapped_labels, scores):\n",
    "                if not full_affiliation_dict[pred]['country']:\n",
    "                    # trying pass instead of break to give time to find the correct country\n",
    "                    pass\n",
    "                elif full_affiliation_dict[pred]['country'] in countries:\n",
    "                    final_pred = pred\n",
    "                    final_score = score\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "    return final_pred, final_score, mapped_labels\n",
    "    \n",
    "def get_similar_preds_to_remove(decoded_string, curr_preds):\n",
    "    \"\"\"\n",
    "    Looks for organizations with similar/matching names and only predicts for one of those organizations.\n",
    "    \"\"\"\n",
    "    preds_to_remove = []\n",
    "    pred_display_names = [full_affiliation_dict[i]['display_name'] for i in curr_preds]\n",
    "    counts_of_preds = Counter(pred_display_names)\n",
    "    \n",
    "    preds_array = np.array(curr_preds)\n",
    "    preds_names_array = np.array(pred_display_names)\n",
    "    \n",
    "    for pred_name in counts_of_preds.items():\n",
    "        temp_preds_to_remove = []\n",
    "        to_use = []\n",
    "        if pred_name[1] > 1:\n",
    "            list_to_check = preds_array[preds_names_array == pred_name[0]].tolist()\n",
    "            for pred in list_to_check:\n",
    "                if string_match_clean(full_affiliation_dict[pred]['city']) in decoded_string:\n",
    "                    to_use.append(pred)\n",
    "                else:\n",
    "                    temp_preds_to_remove.append(pred)\n",
    "            if not to_use:\n",
    "                to_use = temp_preds_to_remove[0]\n",
    "                preds_to_remove += temp_preds_to_remove[1:]\n",
    "            else:\n",
    "                preds_to_remove += temp_preds_to_remove\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return preds_to_remove  \n",
    "\n",
    "\n",
    "def check_for_city_and_country_in_string(raw_sentence, countries, aff_dict_entry):\n",
    "    \"\"\"\n",
    "    Checks for city and country and string for a common name institution.\n",
    "    \"\"\"\n",
    "    if (aff_dict_entry['country'] in countries) & (aff_dict_entry['city'] in raw_sentence):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_final_prediction(basic_pred_score, lang_pred_score, countries, raw_sentence, lang_thresh, basic_thresh):\n",
    "    \"\"\"\n",
    "    Performs the model comparison and filtering to get the final prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting the individual preds and scores for both models\n",
    "    pred_lang, score_lang, mapped_lang = lang_pred_score\n",
    "    pred_basic, score_basic, mapped_basic = basic_pred_score\n",
    "    \n",
    "#     print(f\"lang: {pred_lang} - {score_lang}\")\n",
    "#     print(f\"basic: {pred_basic} - {score_basic}\")\n",
    "    \n",
    "    # Logic for combining the two models\n",
    "    \n",
    "    final_preds = []\n",
    "    final_scores = []\n",
    "    final_cats = []\n",
    "    check_pred = []\n",
    "    if pred_lang == pred_basic:\n",
    "        final_preds.append(pred_lang)\n",
    "        final_scores.append(score_lang)\n",
    "        final_cats.append('model_match')\n",
    "        check_pred.append(pred_lang)\n",
    "    elif score_basic > basic_thresh:\n",
    "        final_preds.append(pred_basic)\n",
    "        final_scores.append(score_basic)\n",
    "        final_cats.append('basic_thresh')\n",
    "        check_pred.append(pred_basic)\n",
    "    elif score_lang > lang_thresh:\n",
    "        final_preds.append(pred_lang)\n",
    "        final_scores.append(score_lang)\n",
    "        final_cats.append('lang_thresh')\n",
    "        check_pred.append(pred_lang)\n",
    "    elif (score_basic > 0.01) & ('China' in countries) & ('Natural Resource' in raw_sentence):\n",
    "        final_preds.append(pred_basic)\n",
    "        final_scores.append(score_basic)\n",
    "        final_cats.append('basic_thresh_second')\n",
    "        check_pred.append(pred_basic)\n",
    "    else:\n",
    "        final_preds.append(-1)\n",
    "        final_scores.append(0.0)\n",
    "        final_cats.append('nothing')\n",
    "        \n",
    "    print(final_preds)\n",
    "    all_mapped = list(set(mapped_lang + mapped_basic))\n",
    "    \n",
    "    decoded_affiliation_string = string_match_clean(raw_sentence)\n",
    "    all_mapped_strings = [full_affiliation_dict[i]['final_names'] for i in all_mapped]\n",
    "          \n",
    "    \n",
    "    matched_preds = []\n",
    "    matched_strings = []\n",
    "#     print(f\"RAW: {raw_sentence}\")\n",
    "#     print(f\"CLEAN: {decoded_affiliation_string}\")\n",
    "#     print(f\"COUNTRIES: {countries}\")\n",
    "    for inst_id, match_strings in zip(all_mapped, all_mapped_strings):\n",
    "#         print(f\"------{full_affiliation_dict[inst_id]['display_name']} - {inst_id}\")\n",
    "        if inst_id not in final_preds:\n",
    "            for match_string in match_strings:\n",
    "#                 print(f\"------{match_string} ({full_affiliation_dict[inst_id]['display_name']} - {inst_id})\")\n",
    "                if match_string in decoded_affiliation_string:\n",
    "#                     print(\"FOUND A MATCH\")\n",
    "                    if not full_affiliation_dict[inst_id]['country']:\n",
    "#                         print(\"######match (no country_dict for aff ID)\")\n",
    "                        matched_preds.append(inst_id)\n",
    "                        matched_strings.append(match_string)\n",
    "                    elif not countries:\n",
    "#                         print(\"######match (no country in string)\")\n",
    "                        if inst_id not in multi_inst_names_ids:\n",
    "                            matched_preds.append(inst_id)\n",
    "                            matched_strings.append(match_string)\n",
    "                        else:\n",
    "                            pass\n",
    "                    elif full_affiliation_dict[inst_id]['country'] in countries:\n",
    "#                         print(\"######match (country matches string)\")\n",
    "                        matched_preds.append(inst_id)\n",
    "                        matched_strings.append(match_string)\n",
    "                    else:\n",
    "                        pass\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    # need to check for institutions that are a subset of another institution\n",
    "    skip_matching = []\n",
    "    for inst_id, matched_string in zip(matched_preds, matched_strings):\n",
    "        for inst_id2, matched_string2 in zip(matched_preds, matched_strings):\n",
    "            if (matched_string in matched_string2) & (matched_string != matched_string2):\n",
    "                skip_matching.append(inst_id)\n",
    "    \n",
    "    if check_pred:\n",
    "        for inst_id, matched_string in zip(matched_preds, matched_strings):\n",
    "            for final_string in full_affiliation_dict[check_pred[0]]['final_names']:\n",
    "                if matched_string in final_string:\n",
    "                    skip_matching.append(inst_id)\n",
    "        \n",
    "    for matched_pred in matched_preds:\n",
    "        if matched_pred not in skip_matching:\n",
    "            final_preds.append(matched_pred)\n",
    "            final_scores.append(0.95)\n",
    "            final_cats.append('string_match')\n",
    "            \n",
    "    if (final_cats[0] == 'nothing') & (len(final_preds)>1):\n",
    "        final_preds = final_preds[1:]\n",
    "        final_scores = final_scores[1:]\n",
    "        final_cats = final_cats[1:]\n",
    "        \n",
    "    # check if many names belong to same organization name (different locations)\n",
    "    if (final_preds[0] != -1) & (len(final_preds)>1):\n",
    "        final_display_names = [full_affiliation_dict[x]['display_name'] for x in final_preds]\n",
    "\n",
    "        if len(final_display_names) == set(final_display_names):\n",
    "            pass\n",
    "        else:\n",
    "            final_preds_after_removal = []\n",
    "            final_scores_after_removal = []\n",
    "            final_cats_after_removal = []\n",
    "            preds_to_remove = get_similar_preds_to_remove(decoded_affiliation_string, final_preds)\n",
    "            for temp_pred, temp_score, temp_cat in zip(final_preds, final_scores, final_cats):\n",
    "                if temp_pred in preds_to_remove:\n",
    "                    pass\n",
    "                else:\n",
    "                    final_preds_after_removal.append(temp_pred)\n",
    "                    final_scores_after_removal.append(temp_score)\n",
    "                    final_cats_after_removal.append(temp_cat)\n",
    "\n",
    "            final_preds = final_preds_after_removal\n",
    "            final_scores = final_scores_after_removal\n",
    "            final_cats = final_cats_after_removal\n",
    "            \n",
    "    \n",
    "    # check for multi-name institution problems (final check)\n",
    "    preds_to_remove = []\n",
    "    if final_preds[0] == -1:\n",
    "        pass\n",
    "    else:\n",
    "        final_department_name_ids = [[x, str(full_affiliation_dict[x]['display_name'])] for x in final_preds if \n",
    "                       (str(full_affiliation_dict[x]['display_name']).startswith(\"Department of\") | \n",
    "                        str(full_affiliation_dict[x]['display_name']).startswith(\"Department for\"))]\n",
    "        if final_department_name_ids:\n",
    "            for temp_id in final_department_name_ids:\n",
    "                if string_match_clean(temp_id[1]) not in string_match_clean(str(raw_sentence).strip()):\n",
    "                    preds_to_remove.append(temp_id[0])\n",
    "                elif not check_for_city_and_country_in_string(raw_sentence, countries, \n",
    "                                                              full_affiliation_dict[temp_id[0]]):\n",
    "                    preds_to_remove.append(temp_id[0])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "\n",
    "        if any(x in final_preds for x in multi_inst_names_ids):\n",
    "            # go through logic\n",
    "            if len(final_preds) == 1:\n",
    "                pred_name = str(full_affiliation_dict[final_preds[0]]['display_name'])\n",
    "                # check if it is exact string match\n",
    "                if (string_match_clean(pred_name) == string_match_clean(str(raw_sentence).strip())):\n",
    "                    final_preds = [-1]\n",
    "                    final_scores = [0.0]\n",
    "                    final_cats = ['nothing']\n",
    "                elif pred_name.startswith(\"Department of\"):\n",
    "                    if (\"College\" in raw_sentence) or (\"University\" in raw_sentence):\n",
    "                        final_preds = [-1]\n",
    "                        final_scores = [0.0]\n",
    "                        final_cats = ['nothing']\n",
    "                    elif string_match_clean(pred_name) not in string_match_clean(str(raw_sentence).strip()):\n",
    "                        final_preds = [-1]\n",
    "                        final_scores = [0.0]\n",
    "                        final_cats = ['nothing']\n",
    "\n",
    "            else:\n",
    "                non_multi_inst_name_preds = [x for x in final_preds if x not in multi_inst_names_ids]\n",
    "                if len(non_multi_inst_name_preds) > 0:\n",
    "                    for temp_pred, temp_score, temp_cat in zip(final_preds, final_scores, final_cats):\n",
    "                        if temp_pred not in non_multi_inst_name_preds:\n",
    "                            aff_dict_temp = full_affiliation_dict[temp_pred]\n",
    "                            if aff_dict_temp['display_name'].startswith(\"Department of\"):\n",
    "                                if (\"College\" in raw_sentence) or (\"University\" in raw_sentence):\n",
    "                                    preds_to_remove.append(temp_pred)\n",
    "                                elif (string_match_clean(str(full_affiliation_dict[temp_pred]['display_name'])) \n",
    "                                      not in string_match_clean(str(raw_sentence).strip())):\n",
    "                                    preds_to_remove.append(temp_pred)\n",
    "                                else:\n",
    "                                    if check_for_city_and_country_in_string(raw_sentence, countries, aff_dict_temp):\n",
    "                                        pass\n",
    "                                    else:\n",
    "                                        preds_to_remove.append(temp_pred)\n",
    "                            # check for city and country\n",
    "                            elif aff_dict_temp['country'] in countries:\n",
    "                                pass\n",
    "                            else:\n",
    "                                preds_to_remove.append(temp_pred)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    true_final_preds = [x for x,y,z in zip(final_preds, final_scores, final_cats) if x not in preds_to_remove]\n",
    "    true_final_scores = [y for x,y,z in zip(final_preds, final_scores, final_cats) if x not in preds_to_remove]\n",
    "    true_final_cats = [z for x,y,z in zip(final_preds, final_scores, final_cats) if x not in preds_to_remove]\n",
    "    \n",
    "    if not true_final_preds:\n",
    "        true_final_preds = [-1]\n",
    "        true_final_scores = [0.0]\n",
    "        true_final_cats = ['nothing']\n",
    "    return [true_final_preds, true_final_scores, true_final_cats]\n",
    "\n",
    "def raw_data_to_predictions(df, lang_thresh, basic_thresh):\n",
    "    \"\"\"\n",
    "    High level function to go from a raw input dataframe to the final dataframe with affiliation\n",
    "    ID prediction.\n",
    "    \"\"\"\n",
    "    # Implementing the functions above\n",
    "    df['lang'] = df['affiliation_string'].apply(get_language)\n",
    "    df['country_in_string'] = df['affiliation_string'].apply(get_country_in_string)\n",
    "    df['comma_split_len'] = df['affiliation_string'].apply(lambda x: len([i if i else \"\" for i in \n",
    "                                                                          x.split(\",\")]))\n",
    "\n",
    "    # Gets initial indicator of whether or not the string should go through the models\n",
    "    df['affiliation_id'] = df.apply(lambda x: get_initial_pred(x.affiliation_string, x.lang, \n",
    "                                                               x.country_in_string, x.comma_split_len), axis=1)\n",
    "    \n",
    "    # Filter out strings that won't go through the models\n",
    "    to_predict = df[df['affiliation_id']==0.0].drop_duplicates(subset=['affiliation_string']).copy()\n",
    "    to_predict['affiliation_id'] = to_predict['affiliation_id'].astype('int')\n",
    "\n",
    "    # Decode text so only ASCII characters are used\n",
    "    to_predict['decoded_text'] = to_predict['affiliation_string'].apply(unidecode)\n",
    "\n",
    "    # Get predictions and scores for each model\n",
    "    to_predict['lang_pred_score'] = get_language_model_prediction(to_predict['decoded_text'].to_list(), \n",
    "                                                                  to_predict['country_in_string'].to_list())\n",
    "    to_predict['basic_pred_score'] = get_basic_model_prediction(to_predict['decoded_text'].to_list(), \n",
    "                                                                to_predict['country_in_string'].to_list())\n",
    "\n",
    "    # Get the final prediction for each affiliation string\n",
    "    to_predict['affiliation_id'] = to_predict.apply(lambda x: \n",
    "                                                    get_final_prediction(x.basic_pred_score, \n",
    "                                                                         x.lang_pred_score, \n",
    "                                                                         x.country_in_string, \n",
    "                                                                         x.affiliation_string, \n",
    "                                                                         lang_thresh, basic_thresh), axis=1)\n",
    "\n",
    "    # Merge predictions to original dataframe to get the same order as the data that was requested\n",
    "    final_df = df[['affiliation_string']].merge(to_predict[['affiliation_string','affiliation_id']], \n",
    "                                                how='left', on='affiliation_string')\n",
    "    \n",
    "#     final_df['affiliation_id'] = final_df['affiliation_id'].fillna(-1).astype('int')\n",
    "    return final_df\n",
    "\n",
    "\n",
    "print(\"Models initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf1840",
   "metadata": {},
   "source": [
    "### Loading all gold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88964fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_display_names(all_preds):\n",
    "    if isinstance(all_preds, float):\n",
    "        return []\n",
    "    elif isinstance(all_preds[0][0], int):\n",
    "        if all_preds[0][0] == -1:\n",
    "            return []\n",
    "        else:\n",
    "            return [f\"{i} - {full_affiliation_dict.get(i).get('display_name')}\" \n",
    "                    if full_affiliation_dict.get(i) else \"-1 - None\" for i in all_preds[0]]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a819b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_display_names(all_labels):\n",
    "    if isinstance(all_labels, list):\n",
    "        return [f\"{i} - {full_affiliation_dict.get(i).get('display_name')}\" \n",
    "                    if full_affiliation_dict.get(i) else \"-1 - None\" for i in all_labels].copy()\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add7e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_all_or_original(all_preds, pred_type='all'):\n",
    "    if isinstance(all_preds, float):\n",
    "        return [-1]\n",
    "    elif isinstance(all_preds[0][0], int):\n",
    "        if pred_type=='all':\n",
    "            return [i for i in all_preds[0]]\n",
    "        else:\n",
    "            final_preds = []\n",
    "            \n",
    "            for preds, scores, cats in zip(all_preds[0], all_preds[1], all_preds[2]):\n",
    "                if cats == 'string_match':\n",
    "                    pass\n",
    "                else:\n",
    "                    final_preds.append(preds)\n",
    "            \n",
    "            if not final_preds:\n",
    "                final_preds = [-1]\n",
    "                \n",
    "            return final_preds\n",
    "    else:\n",
    "        return [-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08921c81",
   "metadata": {},
   "source": [
    "Multiple different datasets were used for testing, refer to the documentation to find out more about them. The following code gathers all the datasets into a single dataframe so they can be run through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ad63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_string = pd.read_csv(\"./labeled_gold_data/multi_string_inst_openalex_labeled.tsv\", sep=\"\\t\") \\\n",
    "    [['paper_id','affiliation_string','labels','dataset']]\n",
    "multi_string['labels'] = multi_string['labels'].apply(lambda x: [int(i) for i in x.split(\"||||\")])\n",
    "\n",
    "cwts_1 = pd.read_csv(\"./labeled_gold_data/cwts_related_labeled.tsv\", sep=\"\\t\") \\\n",
    "    [['paper_id','affiliation_string','labels','dataset']]\n",
    "cwts_1['paper_id'] = cwts_1['paper_id'].apply(lambda x: int(x[1:]))\n",
    "cwts_1['labels'] = cwts_1['labels'].apply(lambda x: [int(i.strip()) for i in x[1:-1].split(\",\")])\n",
    "\n",
    "cwts_2 = pd.read_csv(\"./labeled_gold_data/cwts_no_relation_labeled.tsv\", sep=\"\\t\") \\\n",
    "    [['paper_id','affiliation_string','labels','dataset']]\n",
    "cwts_2['paper_id'] = cwts_2['paper_id'].apply(lambda x: int(x[1:]))\n",
    "cwts_2['labels'] = cwts_2['labels'].apply(lambda x: [int(i.strip()) for i in x[1:-1].split(\",\")])\n",
    "\n",
    "sampled_200 = pd.read_csv(\"./labeled_gold_data/sampled_200_labeled.tsv\", sep=\"\\t\") \\\n",
    "    [['paper_id','affiliation_string','labels','dataset']]\n",
    "sampled_200['labels'] = sampled_200['labels'].apply(lambda x: [int(i.strip()) for i in x[1:-1].split(\",\")])\n",
    "sampled_200['dataset'] = \"gold_random\"\n",
    "\n",
    "all_gold = pd.read_csv(\"./labeled_gold_data/gold_data_institution_parsing_labeled.tsv\", sep=\"\\t\") \\\n",
    "    [['paper_id','affiliation_string','labels','dataset']]\n",
    "all_gold['dataset'] = all_gold['dataset'].replace('gold_500','gold_hard').replace('gold_1000','gold_easy')\n",
    "all_gold['labels'] = all_gold['labels'].apply(lambda x: [int(i.strip()) for i in x[1:-1].split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1dea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([multi_string, cwts_1, cwts_2, sampled_200, all_gold], axis=0) \\\n",
    "    .drop_duplicates(subset=['affiliation_string'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971fabc",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53824b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(labels, preds):\n",
    "    TP=0\n",
    "    FP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    if labels[0] == -1:\n",
    "        if preds[0] != -1:\n",
    "            FP = len(preds)\n",
    "        else:\n",
    "            TN = 1\n",
    "    elif preds[0] == -1:\n",
    "        FN = len(labels)\n",
    "    else:\n",
    "        TP = sum([1 for x in preds if x in labels])\n",
    "        FP = sum([1 for x in preds if x not in labels])\n",
    "        FN = sum([1 for x in labels if x not in preds])\n",
    "        \n",
    "    return [TP, FP, TN, FN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "032677e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preview(aff_obj):\n",
    "    basic_obj = aff_obj[0]\n",
    "    lang_obj = aff_obj[1]\n",
    "    \n",
    "    basic_preds = [str(x) for x in basic_obj[0]]\n",
    "    basic_scores = [round(x, 5) for x in basic_obj[1]]\n",
    "    \n",
    "    lang_preds = [str(x) for x in lang_obj[0]]\n",
    "    lang_scores = [round(x, 5) for x in lang_obj[1]]\n",
    "    \n",
    "    basic_affs = [institutions.get(int(x)) for x in basic_preds]\n",
    "    \n",
    "    basic_ror = [x.get('ror_id') if x else \"\" for x in basic_affs]\n",
    "    basic_aff_name = [x.get('display_name') if x else \"\" for x in basic_affs]\n",
    "    basic_city_name = [x.get('city') if x else \"\" for x in basic_affs]\n",
    "    basic_country_name = [x.get('country') if x else \"\" for x in basic_affs]\n",
    "    \n",
    "    lang_affs = [institutions.get(int(x)) for x in lang_preds]\n",
    "    \n",
    "    lang_ror = [x.get('ror_id') if x else \"\" for x in lang_affs]\n",
    "    lang_aff_name = [x.get('display_name') if x else \"\" for x in lang_affs]\n",
    "    lang_city_name = [x.get('city') if x else \"\" for x in lang_affs]\n",
    "    lang_country_name = [x.get('country') if x else \"\" for x in lang_affs]\n",
    "    \n",
    "    preview_df = pd.DataFrame(zip(basic_preds, lang_preds, basic_ror, lang_ror,\n",
    "                                  basic_aff_name, basic_city_name, basic_country_name,\n",
    "                                  basic_scores,lang_aff_name, lang_city_name, \n",
    "                                  lang_country_name, lang_scores),\n",
    "                             columns=['basic_pred','lang_pred','basic_ror','lang_ror','basic_aff_name',\n",
    "                                      'basic_city_name', 'basic_country_name', 'basic_score','lang_aff_name',\n",
    "                                      'lang_city_name','lang_country_name', 'lang_score'])\n",
    "    \n",
    "    return preview_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a944605",
   "metadata": {},
   "source": [
    "The following code takes the gold datasets and runs all affiliation strings through the model and creates additional columns to make the results easy to explore. There is also a confusion matrix column created which can be used below to generate the precision and recall for the data. Predictions are split up between ones that are made by the model and predictions that are added on using smart string-matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2dcca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_preds = raw_data_to_predictions(all_data, lang_thresh=0.99, basic_thresh=0.99)\\\n",
    "    .merge(all_data[['paper_id','affiliation_string','labels','dataset']])\n",
    "\n",
    "all_preds['preds_name'] = all_preds['affiliation_id'].apply(lambda x: get_preds_display_names(x))\n",
    "\n",
    "all_preds['preds_model_and_string_matching'] = all_preds['affiliation_id'] \\\n",
    "    .apply(lambda x: get_preds_all_or_original(x, 'all'))\n",
    "all_preds['preds_model_only'] = all_preds['affiliation_id']\\\n",
    "    .apply(lambda x: get_preds_all_or_original(x, 'model_only'))\n",
    "\n",
    "all_preds['preds_model_and_string_matching'] = all_preds['preds_model_and_string_matching'] \\\n",
    "    .apply(lambda x: [int(i) if ~np.isnan(i) else -1 for i in x])\n",
    "all_preds['preds_model_only'] = all_preds['preds_model_only']\\\n",
    "    .apply(lambda x: [int(i) if ~np.isnan(i) else -1 for i in x])\n",
    "\n",
    "all_preds['labels'] = all_preds['labels'].apply(lambda x: [int(i) for i in x])\n",
    "all_preds['labels_name'] = all_preds['labels'].apply(lambda x: get_labels_display_names(x))\n",
    "\n",
    "all_preds['conf_mat_model_and_string_matching'] = all_preds\\\n",
    "    .apply(lambda x: get_confusion_matrix(x.labels, x.preds_model_and_string_matching), axis=1)\n",
    "all_preds['conf_mat_model_only'] = all_preds.apply(lambda x: get_confusion_matrix(x.labels, \n",
    "                                                                                  x.preds_model_only), axis=1)\n",
    "\n",
    "all_preds['has_FP'] = all_preds['conf_mat_model_and_string_matching'].apply(lambda x: 1 if x[1] > 0 else 0)\n",
    "all_preds['has_FN'] = all_preds['conf_mat_model_and_string_matching'].apply(lambda x: 1 if x[3] > 0 else 0)\n",
    "\n",
    "all_preds['TP'] = all_preds['conf_mat_model_and_string_matching'].apply(lambda x: x[0])\n",
    "all_preds['FP'] = all_preds['conf_mat_model_and_string_matching'].apply(lambda x: x[1])\n",
    "all_preds['TN'] = all_preds['conf_mat_model_and_string_matching'].apply(lambda x: x[2])\n",
    "all_preds['FN'] = all_preds['conf_mat_model_and_string_matching'].apply(lambda x: x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80a547f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9acf8ca4",
   "metadata": {},
   "source": [
    "### Overall Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d463de6",
   "metadata": {},
   "source": [
    "As mentioned above, the folowing code generates the precision and recall for the data. Predictions are split up between ones that are made by the model (model_only) and predictions that are added on using smart string-matching (model_and_string_matching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a54d3e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- MODEL WITH TEXT MATCHING ---------\n",
      "Precision:  0.947\n",
      "Recall:  0.831\n",
      "\n",
      "--------- MODEL ONLY ---------\n",
      "Precision:  0.951\n",
      "Recall:  0.579\n"
     ]
    }
   ],
   "source": [
    "model_and_string_matching_confs_1000 = all_preds['conf_mat_model_and_string_matching'].tolist()\n",
    "model_only_confs_1000 = all_preds['conf_mat_model_only'].tolist()\n",
    "\n",
    "print(\"--------- MODEL WITH STRING MATCHING ---------\")\n",
    "print(\"Precision: \", round(sum([x[0] for x in model_and_string_matching_confs_1000])/\n",
    "            (sum([x[0] for x in model_and_string_matching_confs_1000]) + \n",
    "             sum([x[1] for x in model_and_string_matching_confs_1000])), 3))\n",
    "\n",
    "print(\"Recall: \", round(sum([x[0] for x in model_and_string_matching_confs_1000])/\n",
    "            (sum([x[0] for x in model_and_string_matching_confs_1000]) + \n",
    "             sum([x[3] for x in model_and_string_matching_confs_1000])), 3))\n",
    "print(\"\")\n",
    "print(\"--------- MODEL ONLY ---------\")\n",
    "\n",
    "print(\"Precision: \", round(sum([x[0] for x in model_only_confs_1000])/\n",
    "            (sum([x[0] for x in model_only_confs_1000]) + sum([x[1] for x in model_only_confs_1000])), 3))\n",
    "\n",
    "print(\"Recall: \", round(sum([x[0] for x in model_only_confs_1000])/\n",
    "            (sum([x[0] for x in model_only_confs_1000]) + sum([x[3] for x in model_only_confs_1000])), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6c338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
